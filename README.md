# AI Search Tool (LangChain + Next.js)

![Project Screenshot](image.png)

Este projeto Ã© um motor de busca inteligente que utiliza InteligÃªncia Artificial para decidir entre fornecer uma resposta direta ou realizar uma busca na web com sumarizaÃ§Ã£o de resultados, utilizando as ferramentas mais modernas de IA e desenvolvimento web.

---

## ğŸš€ Como Funciona

O sistema utiliza **LangChain Expression Language (LCEL)** no backend para orquestrar o fluxo de informaÃ§Ãµes:

1.  **Roteamento Inteligente**: Uma estratÃ©gia de roteamento analisa a pergunta do usuÃ¡rio para decidir se precisa de busca na web (ex: notÃ­cias recentes, comparaÃ§Ãµes de preÃ§os, rankings) ou se pode ser respondida diretamente pelo modelo de IA.
2.  **Web Pipeline**: Caso precise de busca, o sistema utiliza a API da **Tavily** para encontrar os melhores resultados, acessa as pÃ¡ginas, extrai o conteÃºdo e gera um resumo conciso.
3.  **Direct Pipeline**: Para perguntas simples, o modelo responde diretamente de forma rÃ¡pida.
4.  **ValidaÃ§Ã£o**: O resultado final passa por uma camada de validaÃ§Ã£o e "auto-correÃ§Ã£o" para garantir que o formato JSON de saÃ­da esteja sempre correto.

---

## ğŸ› ï¸ Tecnologias Utilizadas

### Backend (`/agent`)
-   **Node.js & Express**: Servidor API robusto.
-   **LangChain**: Framework principal para orquestraÃ§Ã£o de LLMs.
-   **Tavily**: Ferramenta de busca otimizada para agentes de IA.
-   **Provedores de LLM**: Suporte para Google Gemini, OpenAI e Groq.
-   **Zod**: ValidaÃ§Ã£o de esquemas e tipos.

### Frontend (`/client`)
-   **Next.js 15+**: Framework React com App Router.
-   **Tailwind CSS v4**: EstilizaÃ§Ã£o moderna e ultra-rÃ¡pida.
-   **Radix UI**: Componentes acessÃ­veis e customizÃ¡veis.
-   **Lucide React**: Biblioteca de Ã­cones elegantes.

---

## âš™ï¸ ConfiguraÃ§Ã£o e ExecuÃ§Ã£o

### ğŸ³ Rodando com Docker (Recomendado)

A maneira mais rÃ¡pida e fÃ¡cil. **O Docker cuida de tudo para vocÃª** (instalaÃ§Ã£o de dependÃªncias e execuÃ§Ã£o dos serviÃ§os).

1.  Certifique-se de que os arquivos `.env` na pasta `agent` e `client` estejam configurados corretamente.
2.  Na raiz do projeto, execute:

```bash
docker compose up --build
```

> [!TIP]
> Com este comando, vocÃª nÃ£o precisa rodar `npm install` nem `npm run dev` manualmente. O ambiente jÃ¡ sobe pronto para uso.

O frontend estarÃ¡ disponÃ­vel em `http://localhost:3000` e o backend em `http://localhost:5174`.

---

### ğŸ’» Rodando Localmente

#### 1. Backend (Agent)

Navegue atÃ© a pasta do backend e instale as dependÃªncias:

```bash
cd agent
npm install
```

Crie um arquivo `.env` na raiz da pasta `agent` seguindo o modelo:

```env
MODEL_PROVIDER=gemini # ou openai, groq
GOOGLE_API_KEY=sua_chave_aqui
TAVILY_API_KEY=sua_chave_aqui
PORT=5174
ALLOWED_ORIGIN=http://localhost:3000
```

Inicie o servidor de desenvolvimento:

```bash
npm run dev
```

#### 2. Frontend (Client)

Navegue atÃ© a pasta do frontend e instale as dependÃªncias:

```bash
cd ../client
npm install
```

Inicie o servidor do Next.js:

```bash
npm run dev
```

---

## ğŸ“ Estrutura do Projeto

-   `/agent/src/search_tool`: ContÃ©m toda a lÃ³gica da cadeia de busca (LCEL).
-   `/agent/src/routes`: DefiniÃ§Ã£o dos endpoints da API.
-   `/client/src/app`: PÃ¡ginas e rotas do frontend Next.js.
-   `/client/src/components`: Componentes de interface reutilizÃ¡veis.
